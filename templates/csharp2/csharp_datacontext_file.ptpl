%-- DataContext: groups containers by @datasource annotation
%-- Provides cross-container foreign key validation.
%logic
fn to_pascal(name) {
    let parts = name.split("_");
    let result = "";
    for part in parts {
        if part.len() > 0 {
            let first = part.sub_string(0, 1);
            first = first.to_upper();
            let rest = part.sub_string(1);
            result += first + rest;
        }
    }
    result
}

// Collect all namespaces with datasource info (including nested)
let datasource_map = #{};
let ns_stack = [];
for ns in file.namespaces {
    ns_stack.push(ns);
}

while ns_stack.len() > 0 {
    let ns = ns_stack.pop();
    for item in ns.items {
        if item.is_namespace() {
            ns_stack.push(item.as_namespace());
        }
    }
    let ds = ns.datasource;
    if ds == () || ds == "" { continue; }
    let structs = [];
    for item in ns.items {
        if item.is_struct() { structs.push(item.as_struct()); }
    }
    if structs.len() == 0 { continue; }
    if !datasource_map.contains(ds) { datasource_map[ds] = []; }
    datasource_map[ds].push(#{ ns_name: ns.name, structs: structs, ns_datasource: ds });
}

let ds_keys = datasource_map.keys();

// Build cross-container FK info
let fqn_to_ds = #{};
for ds_name in ds_keys {
    for entry in datasource_map[ds_name] {
        for s in entry.structs { fqn_to_ds[s.fqn] = ds_name; }
    }
}
let cross_fks = [];
for ds_name in ds_keys {
    for entry in datasource_map[ds_name] {
        for s in entry.structs {
            for item in s.items {
                if item.is_field() {
                    let f = item.as_field();
                    if f.foreign_key != () {
                        let fk = f.foreign_key;
                        let target_ds = fqn_to_ds[fk.target_table_fqn];
                        if target_ds != () && target_ds != ds_name {
                            let pk_field = "Id";
                            for it2 in s.items { if it2.is_field() { let f2 = it2.as_field(); if f2.is_primary_key { pk_field = f2.name; } } }
                            let target_struct_name = fk.target_table_fqn;
                            if fk.target_table_fqn.contains(".") { let ps = fk.target_table_fqn.split("."); target_struct_name = ps[ps.len() - 1]; }
                            cross_fks.push(#{
                                source_ds: ds_name, source_struct_name: s.name, source_field_name: f.name,
                                source_is_optional: f.field_type.is_option, source_pk: pk_field,
                                target_ds: target_ds, target_fqn: fk.target_table_fqn,
                                target_struct_name: target_struct_name, target_field: fk.target_field,
                                target_field_pascal: to_pascal(fk.target_field)
                            });
                        }
                    }
                }
            }
        }
    }
}

// Build flat lists per datasource for output
let ds_info_list = [];
for ds_name in ds_keys {
    let all_structs = [];
    for entry in datasource_map[ds_name] {
        for s in entry.structs {
            // Extract @load csv/json patterns
            let csv_pattern = "";
            let json_pattern = "";
            for hi in s.header {
                if hi.is_annotation() {
                    let ann = hi.as_annotation();
                    if ann.name == "load" {
                        for p in ann.params {
                            if p.key == "csv" { csv_pattern = p.value; }
                            if p.key == "json" { json_pattern = p.value; }
                        }
                    }
                }
            }
            all_structs.push(#{
                name: s.name, fqn: s.fqn, ns_name: entry.ns_name,
                csv_pattern: csv_pattern, json_pattern: json_pattern
            });
        }
    }
    ds_info_list.push(#{
        ds_name: ds_name,
        pascal_name: to_pascal(ds_name),
        container_type: to_pascal(ds_name) + "Container",
        all_structs: all_structs
    });
}

// Compute context namespace name from file path
let base_name = file.path;
if base_name.contains("/") {
    let pp = base_name.split("/");
    base_name = pp[pp.len() - 1];
}
if base_name.ends_with(".poly") {
    base_name = base_name.sub_string(0, base_name.len() - 5);
}
let context_ns_name = to_pascal(base_name);
%endlogic
%if ds_keys
using System;
using System.Collections.Generic;
using System.IO;
using System.Linq;
using Polygen.Common;
%blank
namespace {{context_ns_name}}.DataContext
{
%for ds_info in ds_info_list
    /// <summary>
    /// Container for '{{ds_info.ds_name}}' datasource tables.
    /// Groups all namespaces marked with @datasource("{{ds_info.ds_name}}").
    /// </summary>
    public class {{ds_info.container_type}}
    {
        /// <summary>
        /// Gets or sets the root directory for resolving relative file paths.
        /// </summary>
        public string RootDirectory { get; set; } = ".";
%blank
%for st in ds_info.all_structs
        /// <summary>{{st.name}} table from {{st.ns_name}} namespace.</summary>
        public global::{{st.ns_name}}.Container.{{st.name}}Table {{st.name}}s { get; } = new();
%endfor
%blank
        public {{ds_info.container_type}}(string rootDirectory = ".")
        {
            RootDirectory = rootDirectory;
        }
%blank
        /// <summary>
        /// Clears all data from all tables in this container.
        /// </summary>
        public void Clear()
        {
%for st in ds_info.all_structs
            {{st.name}}s.Clear();
%endfor
        }
%blank
        /// <summary>
        /// Loads all tables from CSV files using @load annotation patterns.
        /// </summary>
        public void LoadFromCsv(char separator = ',', CsvUtils.GapMode gapMode = CsvUtils.GapMode.Break)
        {
%for st in ds_info.all_structs
%if st.csv_pattern != ""
            // {{st.name}}: @load(csv: "{{st.csv_pattern}}")
            foreach (var item in Csv.{{st.ns_name}}.{{st.name}}.ReadRowsWithHeader(
                Path.Combine(RootDirectory, "{{st.csv_pattern}}"), separator, gapMode))
            {
                {{st.name}}s.Add(item);
            }
%endif
%endfor
        }
%blank
        /// <summary>
        /// Loads all tables from CSV files in a directory.
        /// Files should be named: {TableName}.csv
        /// </summary>
        public void LoadFromCsvDirectory(string directoryPath, char separator = ',', CsvUtils.GapMode gapMode = CsvUtils.GapMode.Break)
        {
%for st in ds_info.all_structs
%logic
let var_name = st.name.to_lower() + "Path";
%endlogic
            var {{var_name}} = Path.Combine(directoryPath, "{{st.name}}.csv");
            if (File.Exists({{var_name}}))
            {
                foreach (var item in Csv.{{st.ns_name}}.{{st.name}}.ReadRowsWithHeader({{var_name}}, separator, gapMode))
                    {{st.name}}s.Add(item);
            }
%endfor
        }
%blank
        /// <summary>
        /// Loads all tables from JSON files using @load annotation patterns.
        /// </summary>
        public void LoadFromJson()
        {
%for st in ds_info.all_structs
%if st.json_pattern != ""
            // {{st.name}}: @load(json: "{{st.json_pattern}}")
            {
                var json = File.ReadAllText(Path.Combine(RootDirectory, "{{st.json_pattern}}"));
                var items = System.Text.Json.JsonSerializer.Deserialize<List<global::{{st.ns_name}}.{{st.name}}>>(json);
                if (items != null)
                    foreach (var item in items)
                        {{st.name}}s.Add(item);
            }
%endif
%endfor
        }
%blank
        /// <summary>
        /// Loads all tables from JSON files in a directory.
        /// Files should be named: {TableName}.json
        /// </summary>
        public void LoadFromJsonDirectory(string directoryPath)
        {
%for st in ds_info.all_structs
%logic
let var_name = st.name.to_lower() + "Path";
%endlogic
            var {{var_name}} = Path.Combine(directoryPath, "{{st.name}}.json");
            if (File.Exists({{var_name}}))
            {
                var json = File.ReadAllText({{var_name}});
                var items = System.Text.Json.JsonSerializer.Deserialize<List<global::{{st.ns_name}}.{{st.name}}>>(json);
                if (items != null)
                    foreach (var item in items)
                        {{st.name}}s.Add(item);
            }
%endfor
        }
%blank
        /// <summary>
        /// Loads all tables from a binary file.
        /// </summary>
        public void LoadFromBinary(string filePath)
        {
            using var fs = File.OpenRead(filePath);
            using var br = new BinaryReader(fs);
%for st in ds_info.all_structs
%logic
let reader_ns = if st.ns_name != "" { st.ns_name } else { "Global" };
%endlogic
            {
                var count = br.ReadInt32();
                for (var i = 0; i < count; i++)
                    {{st.name}}s.Add({{reader_ns}}.BinaryReaders.Read{{st.name}}(br));
            }
%endfor
        }
%blank
        /// <summary>
        /// Saves all tables to a binary file.
        /// </summary>
        public void SaveToBinary(string filePath)
        {
            using var fs = File.Create(filePath);
            using var bw = new BinaryWriter(fs);
%for st in ds_info.all_structs
%logic
let writer_ns = if st.ns_name != "" { st.ns_name } else { "Global" };
%endlogic
            bw.Write({{st.name}}s.Count);
            foreach (var item in {{st.name}}s)
                {{writer_ns}}.BinaryWriters.Write{{st.name}}(bw, item);
%endfor
        }
%blank
        /// <summary>
        /// Validates all tables within this container.
        /// Note: Does not validate cross-container foreign keys. Use DataContext.ValidateAll() for that.
        /// </summary>
        public ValidationResult ValidateAll()
        {
            var result = new ValidationResult();
%for st in ds_info.all_structs
            result.Merge({{st.name}}s.Validate());
%endfor
            return result;
        }
    }
%blank
%endfor
    /// <summary>
    /// Root data context that holds all datasource containers.
    /// Provides cross-container foreign key validation.
    /// </summary>
    public class DataContext
    {
%for ds_info in ds_info_list
        /// <summary>Container for '{{ds_info.ds_name}}' datasource.</summary>
        public {{ds_info.container_type}} {{ds_info.pascal_name}} { get; } = new();
%endfor
%blank
        public DataContext()
        {
        }
%blank
        public DataContext(string rootDirectory)
        {
%for ds_info in ds_info_list
            {{ds_info.pascal_name}}.RootDirectory = rootDirectory;
%endfor
        }
%blank
        /// <summary>
        /// Sets the root directory for all containers.
        /// </summary>
        public void SetRootDirectory(string rootDirectory)
        {
%for ds_info in ds_info_list
            {{ds_info.pascal_name}}.RootDirectory = rootDirectory;
%endfor
        }
%blank
        /// <summary>
        /// Clears all data from all containers.
        /// </summary>
        public void Clear()
        {
%for ds_info in ds_info_list
            {{ds_info.pascal_name}}.Clear();
%endfor
        }
%blank
        /// <summary>
        /// Validates all tables in all containers, including cross-container foreign keys.
        /// </summary>
        /// <returns>A ValidationResult containing any validation errors.</returns>
        public ValidationResult ValidateAll()
        {
            var result = new ValidationResult();
%blank
            // Validate each container internally
%for ds_info in ds_info_list
            result.Merge({{ds_info.pascal_name}}.ValidateAll());
%endfor
%blank
            // Validate cross-container foreign keys
            result.Merge(ValidateCrossContainerReferences());
%blank
            return result;
        }
%blank
        /// <summary>
        /// Validates all tables and throws an exception if any errors are found.
        /// </summary>
        /// <exception cref="ValidationException">Thrown when validation fails.</exception>
        public void ValidateOrThrow()
        {
            var result = ValidateAll();
            if (!result.IsValid)
                throw new ValidationException(result);
        }
%blank
        /// <summary>
        /// Validates foreign key references that cross container boundaries.
        /// </summary>
        private ValidationResult ValidateCrossContainerReferences()
        {
            var result = new ValidationResult();
%blank
%if !cross_fks
            // No cross-container foreign keys defined
%else
%for fk in cross_fks
%logic
let source_prop = to_pascal(fk.source_ds);
let target_prop = to_pascal(fk.target_ds);
%endlogic
            // {{fk.source_struct_name}}.{{fk.source_field_name}} -> {{fk.target_fqn}}.{{fk.target_field}}
            foreach (var item in {{source_prop}}.{{fk.source_struct_name}}s)
            {
%if fk.source_is_optional
                if (item.{{fk.source_field_name}}.HasValue)
                {
                    if (!{{target_prop}}.{{fk.target_struct_name}}s.TryGetBy{{fk.target_field_pascal}}(item.{{fk.source_field_name}}.Value, out _))
                    {
                        result.AddError(
                            "{{fk.source_struct_name}}",
                            item.{{fk.source_pk}}?.ToString() ?? "(null)",
                            "{{fk.source_field_name}}",
                            $"Cross-container FK reference not found in {{fk.target_ds}}.{{fk.target_struct_name}}: {item.{{fk.source_field_name}}.Value}");
                    }
                }
%else
                if (!{{target_prop}}.{{fk.target_struct_name}}s.TryGetBy{{fk.target_field_pascal}}(item.{{fk.source_field_name}}, out _))
                {
                    result.AddError(
                        "{{fk.source_struct_name}}",
                        item.{{fk.source_pk}}?.ToString() ?? "(null)",
                        "{{fk.source_field_name}}",
                        $"Cross-container FK reference not found in {{fk.target_ds}}.{{fk.target_struct_name}}: {item.{{fk.source_field_name}}}");
                }
%endif
            }
%blank
%endfor
%endif
            return result;
        }
    }
}
%endif
